{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOR-OFBjFAQ"
      },
      "source": [
        "# üé® SDXL Vintage Illustration Notebook ‚Äî PRO\n",
        "\n",
        "Stable Diffusion XL / Turbo / SD 1.5 preconfigured for **vintage ink+watercolor** illustrations (old book style, retro cartoon aesthetic).\n",
        "\n",
        "### Included\n",
        "- **Mode Selector** (CPU / GPU basic / GPU optimal via `CONFIG`)\n",
        "- **Gallery Manager (Flask web UI)** + **Logs** page\n",
        "- **Text2Img** (default vintage style + custom scene prompt)\n",
        "- **Img2Img** (photo ‚Üí vintage illustration)\n",
        "- **ControlNet (Canny)** for pose/contour consistency\n",
        "- **Upscale** (x4) for higher resolution\n",
        "- **Color tone control** (dropdown presets + custom override)\n",
        "- Saving images + JSON metadata to `/content/outputs` (timestamped)\n",
        "\n"
      ],
      "id": "vIOR-OFBjFAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚úÖ Tips\n",
        "\n",
        "- Change **`color_tone`** or **`custom_tone`** any time, then regenerate.\n",
        "- Use **`seed=None`** for randomization, or set a fixed integer for repeatability.\n",
        "- For **Img2Img**, tweak **`strength`**:\n",
        "  - lower = closer to original,\n",
        "  - higher = stronger style.\n",
        "- **ControlNet (Canny)** retains silhouette/contours. For different looks, adjust **`canny_low`/`canny_high`**.\n",
        "- If memory errors occur, run **`free_memory()`** and re-run only the needed loader.\n"
      ],
      "metadata": {
        "id": "PyfLfc6z13Ol"
      },
      "id": "PyfLfc6z13Ol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Repo init\n",
        "import os\n",
        "\n",
        "repo_name = \"sd-colab-gallery\"\n",
        "repo_url  = f\"https://github.com/tekswirl25/{repo_name}.git\"\n",
        "repo_dir  = f\"/content/{repo_name}\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"üì• Cloning repo...\")\n",
        "    !git clone {repo_url} {repo_dir}\n",
        "else:\n",
        "    print(\"üîÑ Repo exists, pulling latest changes...\")\n",
        "    %cd {repo_dir}\n",
        "    !git pull\n",
        "\n",
        "%cd {repo_dir}\n",
        "print(\"‚úÖ Repo ready at\", repo_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "60M1dlBE8Hgs"
      },
      "id": "60M1dlBE8Hgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß 1 Config init\n",
        "import os, sys, pathlib, torch\n",
        "\n",
        "# repo_dir –∑–∞–¥–∞—ë—Ç—Å—è –≤ üöÄ Repo init\n",
        "sys.path.append(repo_dir)\n",
        "\n",
        "# –í–∫–ª—é—á–∞–µ–º fallback –¥–ª—è macOS (–Ω–∞ Colab –Ω–µ –º–µ—à–∞–µ—Ç)\n",
        "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "\n",
        "from scripts.logger import log_info\n",
        "from scripts.config import VARIANTS, VARIANT_MODELS\n",
        "\n",
        "CONFIG = {\n",
        "    \"MODE\": \"GPU_OPTIMAL\",       # \"CPU\", \"GPU_BASIC\", \"GPU_OPTIMAL\"\n",
        "    \"MODEL_VARIANT\": \"SDXL\",     # \"SDXL\", \"TURBO\", \"SD15\"\n",
        "    \"OUTPUT_DIR\": \"/content/outputs\",\n",
        "}\n",
        "os.makedirs(CONFIG[\"OUTPUT_DIR\"], exist_ok=True)\n",
        "\n",
        "VARIANT = VARIANTS[CONFIG[\"MODEL_VARIANT\"]]\n",
        "DEFAULTS = VARIANT[\"defaults\"]\n",
        "AUTO_UPSCALE = VARIANT[\"auto_upscale\"]\n",
        "\n",
        "DEVICE = \"cuda\" if (VARIANT_MODELS.get(\"device\",\"cuda\")==\"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
        "DTYPE  = torch.float16 if str(VARIANT_MODELS.get(\"dtype\",\"fp16\")).lower() in (\"fp16\",\"float16\",\"half\") else torch.float32\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "log_info(f\"Config initialized: {CONFIG}, device={DEVICE}, dtype={DTYPE}\")\n"
      ],
      "metadata": {
        "id": "uieDzdxEsR1w",
        "outputId": "b2d803e7-3900-4a12-fc94-a7f6b26e8112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "id": "uieDzdxEsR1w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 2 Server (Flask gallery + logs)\n",
        "from scripts.gallery_manager import start_gallery\n",
        "start_gallery(CONFIG[\"OUTPUT_DIR\"], port=8000, in_colab=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-PGUOEUskan"
      },
      "id": "F-PGUOEUskan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 3 Install dependencies\n",
        "!pip -q install diffusers==0.29.0 transformers accelerate xformers safetensors opencv-python-headless ipywidgets flask nest_asyncio\n",
        "\n",
        "import os, torch\n",
        "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "print(\"Dependencies installed. Torch version:\", torch.__version__)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zTZsBflTkxBK",
        "outputId": "702c90c7-77f0-418d-b67d-b27df23a89bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zTZsBflTkxBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîÅ 4 Imports & utils\n",
        "from scripts.utils import (\n",
        "    ts_now, base_name, save_image_and_meta,\n",
        "    free_memory, list_images, canny_from_image\n",
        ")\n",
        "from scripts.logger import log_info, log_error\n",
        "log_info(f\"Utils loaded. OUTPUT_DIR={CONFIG['OUTPUT_DIR']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XxvouF_9xe24"
      },
      "id": "XxvouF_9xe24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† 5 Model loaders\n",
        "from scripts.loaders import (\n",
        "    get_txt2img_pipe,\n",
        "    get_img2img_pipe,\n",
        "    get_controlnet_pipe,\n",
        "    get_upscale_pipe,\n",
        "    reset_pipes\n",
        ")\n",
        "log_info(f\"Loader functions ready for variant: {CONFIG['MODEL_VARIANT']}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNl-njQ9xr7X"
      },
      "id": "dNl-njQ9xr7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé® 6 Style base & Prompt builder\n",
        "from scripts.prompt_builder import build_prompt\n",
        "\n",
        "user_prompt = \"A thoughtful man, slightly resembling Elon Musk.\"  #@param {type:\"string\"}\n",
        "base_style  = \"illustration\"  #@param [\"photoreal\",\"illustration\",\"anime\"]\n",
        "color_tone  = \"vintage\"       #@param [\"warm\",\"cool\",\"vintage\"]\n",
        "negative    = \"\"              #@param {type:\"string\"}\n",
        "\n",
        "final_prompt = build_prompt(user_prompt, style=base_style, tone=color_tone)\n",
        "log_info(f\"Prompt built. style={base_style}, tone={color_tone}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Nx6OKvkvJZpx"
      },
      "id": "Nx6OKvkvJZpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Text2Img\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "\n",
        "pipe = get_txt2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "steps     = DEFAULTS[\"txt2img_steps\"]\n",
        "cfg_scale = DEFAULTS[\"txt2img_cfg\"]\n",
        "height, width = DEFAULTS[\"img_size\"]\n",
        "\n",
        "seed = 12345      #@param {type:\"number\"}\n",
        "n    = 1          #@param {type:\"number\"}\n",
        "\n",
        "saved = []\n",
        "for _ in range(n):\n",
        "    generator = torch.manual_seed(seed)\n",
        "    out = pipe(\n",
        "        prompt=final_prompt,\n",
        "        negative_prompt=negative or None,\n",
        "        height=height, width=width,\n",
        "        guidance_scale=cfg_scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "    )\n",
        "    im = out.images[0]\n",
        "    meta = {\n",
        "        \"mode\": \"text2img\",\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative\": negative,\n",
        "        \"steps\": steps,\n",
        "        \"cfg_scale\": cfg_scale,\n",
        "        \"size\": [height, width],\n",
        "        \"seed\": seed,\n",
        "        \"timestamp\": ts_now(),\n",
        "    }\n",
        "    p, _ = save_image_and_meta(im, prefix=\"text2img\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "    saved.append(p)\n",
        "\n",
        "log_info(f\"Text2Img saved: {saved}\")\n"
      ],
      "metadata": {
        "id": "dh-8iJ3k3lPf"
      },
      "id": "dh-8iJ3k3lPf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Img2Img\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"img2img\"]\n",
        "\n",
        "src_path = \"\"    #@param {type:\"string\"}\n",
        "strength = 0.6   #@param {type:\"number\"}\n",
        "seed     = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not src_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (src_path)\")\n",
        "\n",
        "image = Image.open(src_path).convert(\"RGB\")\n",
        "pipe_i2i = get_img2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "out = pipe_i2i(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=image,\n",
        "    strength=strength,\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"img2img\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"strength\": strength,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"img2img\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"Img2Img saved: {p}\")\n"
      ],
      "metadata": {
        "id": "laNfGN0x3vpo"
      },
      "id": "laNfGN0x3vpo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß≠ 9 ControlNet (Canny)\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "\n",
        "if variant == \"TURBO\":\n",
        "    base_model_id = VARIANT_MODELS[\"TURBO\"][\"controlnet_model\"]\n",
        "else:\n",
        "    base_model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "\n",
        "controlnet_id = VARIANT_MODELS[variant][\"controlnet\"]\n",
        "\n",
        "pipe_canny = get_controlnet_pipe(base_model_id, controlnet_id, DEVICE, DTYPE)\n",
        "\n",
        "control_path = \"\"   #@param {type:\"string\"}\n",
        "low_thr = 100       #@param {type:\"number\"}\n",
        "high_thr = 200      #@param {type:\"number\"}\n",
        "seed     = 12345    #@param {type:\"number\"}\n",
        "\n",
        "if not control_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è Canny (control_path)\")\n",
        "\n",
        "src = Image.open(control_path).convert(\"RGB\")\n",
        "canny_img = canny_from_image(src, low_thr, high_thr)\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "out = pipe_canny(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=canny_img,\n",
        "    control_image=canny_img,\n",
        "    num_inference_steps=DEFAULTS[\"controlnet_steps\"],\n",
        "    guidance_scale=DEFAULTS[\"controlnet_cfg\"],\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"controlnet_canny\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"low_thr\": low_thr,\n",
        "    \"high_thr\": high_thr,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"controlnet\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"ControlNet saved: {p}\")\n"
      ],
      "metadata": {
        "id": "r1w0gFWF35cd"
      },
      "id": "r1w0gFWF35cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚¨ÜÔ∏è 10 Upscale x4\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "up_id   = VARIANT_MODELS[variant][\"upscale\"]\n",
        "\n",
        "pipe_up = get_upscale_pipe(up_id, DEVICE, DTYPE)\n",
        "\n",
        "in_path = \"\"   #@param {type:\"string\"}\n",
        "seed    = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not in_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (in_path)\")\n",
        "\n",
        "img = Image.open(in_path).convert(\"RGB\")\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "out = pipe_up(image=img, prompt=final_prompt, generator=generator)\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"upscale_x4\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"upscale\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"Upscale saved: {p}\")\n"
      ],
      "metadata": {
        "id": "CKFMylGe4KfI"
      },
      "id": "CKFMylGe4KfI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
