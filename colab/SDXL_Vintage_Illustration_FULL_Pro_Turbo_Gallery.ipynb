{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOR-OFBjFAQ"
      },
      "source": [
        "# üé® SDXL Vintage Illustration Notebook ‚Äî PRO\n",
        "\n",
        "Stable Diffusion XL / Turbo / SD 1.5 preconfigured for **vintage ink+watercolor** illustrations (old book style, retro cartoon aesthetic).\n",
        "\n",
        "### Included\n",
        "- **Mode Selector** (CPU / GPU basic / GPU optimal via `CONFIG`)\n",
        "- **Gallery Manager (Flask web UI)** + **Logs** page\n",
        "- **Text2Img** (default vintage style + custom scene prompt)\n",
        "- **Img2Img** (photo ‚Üí vintage illustration)\n",
        "- **ControlNet (Canny)** for pose/contour consistency\n",
        "- **Upscale** (x4) for higher resolution\n",
        "- **Color tone control** (dropdown presets + custom override)\n",
        "- Saving images + JSON metadata to `/content/outputs` (timestamped)\n",
        "\n"
      ],
      "id": "vIOR-OFBjFAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚úÖ Tips\n",
        "\n",
        "- Change **`color_tone`** or **`custom_tone`** any time, then regenerate.\n",
        "- Use **`seed=None`** for randomization, or set a fixed integer for repeatability.\n",
        "- For **Img2Img**, tweak **`strength`**:\n",
        "  - lower = closer to original,\n",
        "  - higher = stronger style.\n",
        "- **ControlNet (Canny)** retains silhouette/contours. For different looks, adjust **`canny_low`/`canny_high`**.\n",
        "- If memory errors occur, run **`free_memory()`** and re-run only the needed loader.\n"
      ],
      "metadata": {
        "id": "PyfLfc6z13Ol"
      },
      "id": "PyfLfc6z13Ol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Repo init\n",
        "from scripts.repo_init import init_repo\n",
        "\n",
        "REPO_NAME = \"sd-colab-gallery\"\n",
        "ORIGIN_URL = f\"https://github.com/tekswirl25/{REPO_NAME}.git\"\n",
        "UPSTREAM_URL = \"\"  # –µ—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—à—å —Å —Ñ–æ—Ä–∫–æ–º, —É–∫–∞–∂–∏ URL –∞–ø—Å—Ç—Ä–∏–º–∞\n",
        "\n",
        "repo_dir = init_repo(REPO_NAME, ORIGIN_URL, UPSTREAM_URL)\n",
        "\n"
      ],
      "metadata": {
        "id": "-M75dqeXXKXT"
      },
      "id": "-M75dqeXXKXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Install gradio\n",
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "E2WPWT40clpf"
      },
      "id": "E2WPWT40clpf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üåê Start Gradio server (Logs + Gallery)\n",
        "from scripts.server_gradio import start_gradio_server\n",
        "\n",
        "server = start_gradio_server(\"/content/outputs\")\n",
        "\n",
        "if server and hasattr(server, \"share_url\") and server.share_url:\n",
        "    print(f\"‚úÖ Gradio server running at: {server.share_url}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Gradio server started, but no public URL detected\")\n"
      ],
      "metadata": {
        "id": "xZ-fSmJ2ZcPi"
      },
      "id": "xZ-fSmJ2ZcPi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 3 Install dependencies\n",
        "import os\n",
        "\n",
        "if MODE in [\"GPU_OPTIMAL\", \"GPU_BASIC\"]:\n",
        "    # GPU-–≤–∞—Ä–∏–∞–Ω—Ç—ã: –Ω—É–∂–µ–Ω torch —Å CUDA\n",
        "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "!pip install diffusers==0.29.0 transformers accelerate safetensors xformers\n",
        "\n",
        "# –û–±—â–∏–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤\n",
        "!pip install opencv-python-headless pillow flask nest_asyncio ipywidgets\n",
        "\n",
        "print(f\"‚úÖ Dependencies installed for MODE={MODE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pXT6a4Zk6lOC"
      },
      "id": "pXT6a4Zk6lOC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üåê Start Flask server\n",
        "#from scripts.server import start_server\n",
        "#from scripts.logger import log_info\n",
        "\n",
        "#start_server(CONFIG[\"OUTPUT_DIR\"], port=8000)\n",
        "\n",
        "#log_info(\"‚úÖ Flask server started on http://127.0.0.1:8000\")\n",
        "#log_info(\"üåê Logs available at /logs\")\n",
        "#log_info(\"üåê Gallery available at /gallery\")\n"
      ],
      "metadata": {
        "id": "AhZ8Y7fdTPmT"
      },
      "id": "AhZ8Y7fdTPmT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß 1 Config init\n",
        "import os, sys, torch\n",
        "sys.path.append(repo_dir)  # üöÄ Repo init\n",
        "\n",
        "# -----------------------------\n",
        "# UI-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤—ã–±–æ—Ä—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º)\n",
        "ENV_MODE        = \"GPU\"        #@param [\"GPU\", \"CPU\"]\n",
        "PROGRAM_VERSION = \"SDXL\"       #@param [\"SDXL\", \"SDXL_TURBO\", \"SD15\"]\n",
        "MODE            = \"GPU_OPTIMAL\" #@param [\"GPU_OPTIMAL\", \"GPU_BASIC\", \"CPU\"]\n",
        "OUTPUT_DIR      = \"/content/outputs\"\n",
        "# -----------------------------\n",
        "\n",
        "# HuggingFace token (Colab Secrets –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)\n",
        "hf_token = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get(\"HF_TOKEN\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "from scripts.config import init_config\n",
        "from scripts.logger import log_info, log_error\n",
        "\n",
        "CONFIG, VARIANT, DEFAULTS, AUTO_UPSCALE = init_config(\n",
        "    model_variant=PROGRAM_VERSION,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    hf_token=hf_token,\n",
        "    mode=MODE,\n",
        "    env_mode=ENV_MODE  # –Ω–æ–≤—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç\n",
        ")\n",
        "\n",
        "log_info(f\"Torch version: {torch.__version__}\")\n",
        "log_info(f\"Device: {CONFIG['DEVICE']} | DType: {CONFIG['DTYPE']} | Mode: {CONFIG['MODE']}\")\n"
      ],
      "metadata": {
        "id": "uieDzdxEsR1w"
      },
      "id": "uieDzdxEsR1w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîç 1.1 –¢–µ—Å—Ç ENV_MODE\n",
        "from scripts.config import init_config\n",
        "\n",
        "# CPU —Ä–µ–∂–∏–º\n",
        "config_cpu, *_ = init_config(model_variant=\"SDXL\", env_mode=\"CPU\")\n",
        "print(\"CPU test:\", config_cpu[\"DEVICE\"], config_cpu[\"DTYPE\"])\n",
        "\n",
        "# GPU —Ä–µ–∂–∏–º (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ CUDA)\n",
        "config_gpu, *_ = init_config(model_variant=\"SDXL\", env_mode=\"GPU\")\n",
        "print(\"GPU test:\", config_gpu[\"DEVICE\"], config_gpu[\"DTYPE\"])\n"
      ],
      "metadata": {
        "id": "Tl0chVwhN9ca"
      },
      "id": "Tl0chVwhN9ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 2 Server (Flask gallery + logs)\n",
        "from scripts.gallery_manager import start_gallery\n",
        "start_gallery(CONFIG[\"OUTPUT_DIR\"], port=8000, in_colab=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-PGUOEUskan"
      },
      "id": "F-PGUOEUskan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 3 Install dependencies (Colab universal)\n",
        "!pip install --upgrade pip\n",
        "\n",
        "import os, sys, subprocess\n",
        "\n",
        "if ENV_MODE == \"GPU\":\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xformers\"])\n",
        "else:  # CPU fallback\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cpu\"])\n",
        "    print(\"‚ö†Ô∏è CPU mode selected: xformers skipped\")\n",
        "\n",
        "# –û–±—â–∏–π —Å—Ç–µ–∫\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "    \"diffusers==0.29.0\", \"transformers\", \"accelerate\", \"safetensors\",\n",
        "    \"ipywidgets\", \"opencv-python-headless\", \"pillow\", \"flask\", \"nest_asyncio\"])\n",
        "\n",
        "import torch\n",
        "print(\"‚úÖ Dependencies installed. Torch version:\", torch.__version__)\n"
      ],
      "metadata": {
        "id": "zTZsBflTkxBK"
      },
      "id": "zTZsBflTkxBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîÅ 4 Imports & utils\n",
        "from scripts.utils import (\n",
        "    ts_now, base_name, save_image_and_meta,\n",
        "    free_memory, list_images, canny_from_image\n",
        ")\n",
        "from scripts.logger import log_info, log_error\n",
        "log_info(f\"Utils loaded. OUTPUT_DIR={CONFIG['OUTPUT_DIR']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XxvouF_9xe24"
      },
      "id": "XxvouF_9xe24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† 5 Model loaders\n",
        "from scripts.loaders import (\n",
        "    get_txt2img_pipe,\n",
        "    get_img2img_pipe,\n",
        "    get_controlnet_pipe,\n",
        "    get_upscale_pipe,\n",
        "    reset_pipes\n",
        ")\n",
        "log_info(f\"Loader functions ready for variant: {CONFIG['MODEL_VARIANT']}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNl-njQ9xr7X"
      },
      "id": "dNl-njQ9xr7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé® 6 Style base & Prompt builder\n",
        "from scripts.prompt_builder import build_prompt\n",
        "\n",
        "user_prompt = \"A thoughtful man, slightly resembling donald trump.\"  #@param {type:\"string\"}\n",
        "base_style  = \"illustration\"  #@param [\"photoreal\",\"illustration\",\"anime\"]\n",
        "color_tone  = \"vintage\"       #@param [\"warm\",\"cool\",\"vintage\"]\n",
        "negative    = \"\"              #@param {type:\"string\"}\n",
        "\n",
        "final_prompt = build_prompt(user_prompt, style=base_style, tone=color_tone)\n",
        "log_info(f\"Prompt built. style={base_style}, tone={color_tone}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Nx6OKvkvJZpx"
      },
      "id": "Nx6OKvkvJZpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Text2Img\n",
        "from PIL import Image\n",
        "from scripts.config import CONFIG, DEVICE, DTYPE, VARIANT_MODELS, DEFAULTS\n",
        "from scripts.loaders import get_txt2img_pipe\n",
        "from scripts.utils import save_image_and_meta, ts_now\n",
        "from scripts.logger import log_info\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "\n",
        "pipe = get_txt2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "steps     = DEFAULTS[\"txt2img_steps\"]\n",
        "cfg_scale = DEFAULTS[\"txt2img_cfg\"]\n",
        "height, width = DEFAULTS[\"img_size\"]\n",
        "\n",
        "seed = 12345      #@param {type:\"number\"}\n",
        "n    = 1          #@param {type:\"number\"}\n",
        "\n",
        "saved = []\n",
        "for _ in range(n):\n",
        "    generator = torch.manual_seed(seed)\n",
        "    out = pipe(\n",
        "        prompt=final_prompt,\n",
        "        negative_prompt=negative or None,\n",
        "        height=height, width=width,\n",
        "        guidance_scale=cfg_scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "    )\n",
        "    im = out.images[0]\n",
        "    meta = {\n",
        "        \"mode\": \"text2img\",\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative\": negative,\n",
        "        \"steps\": steps,\n",
        "        \"cfg_scale\": cfg_scale,\n",
        "        \"size\": [height, width],\n",
        "        \"seed\": seed,\n",
        "        \"timestamp\": ts_now(),\n",
        "    }\n",
        "    p, _ = save_image_and_meta(im, prefix=\"text2img\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "    saved.append(p)\n",
        "\n",
        "log_info(f\"Text2Img saved: {saved}\")\n"
      ],
      "metadata": {
        "id": "dh-8iJ3k3lPf"
      },
      "id": "dh-8iJ3k3lPf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SadkqV9_LbF6"
      },
      "id": "SadkqV9_LbF6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì§ Upload image (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è Img2Img / ControlNet)\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# –ú–æ–∂–Ω–æ –∑–∞—Ä–∞–Ω–µ–µ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é:\n",
        "src_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "uploaded = files.upload()  # –æ—Ç–∫—Ä–æ–µ—Ç –æ–∫–Ω–æ \"Browse\"\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    src_path = os.path.join(\"/content\", filename)\n",
        "    file_size = os.path.getsize(src_path) / 1024\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "    print(f\"üìÇ Saved to: {src_path} ({file_size:.1f} KB)\")\n",
        "elif src_path:\n",
        "    print(f\"‚ö†Ô∏è No upload. –ò—Å–ø–æ–ª—å–∑—É—é –≤—Ä—É—á–Ω—É—é –∑–∞–¥–∞–Ω–Ω—ã–π –ø—É—Ç—å: {src_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded and src_path –ø—É—Å—Ç–æ–π. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")\n"
      ],
      "metadata": {
        "id": "A8gIu3i7LQqd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "A8gIu3i7LQqd"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Img2Img\n",
        "from scripts.pipelines import run_img2img\n",
        "\n",
        "strength = 0.6   #@param {type:\"number\"}\n",
        "seed     = 12345 #@param {type:\"number\"}\n",
        "src_path = \"\"    #@param {type:\"string\"}\n",
        "\n",
        "saved = run_img2img(\n",
        "    user_prompt=user_prompt,\n",
        "    style=base_style,\n",
        "    tone=color_tone,\n",
        "    negative=negative,\n",
        "    src_path=src_path,\n",
        "    CONFIG=CONFIG,\n",
        "    DEFAULTS=DEFAULTS,\n",
        "    strength=strength,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Img2Img completed.\")\n",
        "print(\"üìÇ Saved files:\", saved if isinstance(saved, list) else [saved])\n"
      ],
      "metadata": {
        "id": "DpIwpsa1Lf35"
      },
      "id": "DpIwpsa1Lf35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì§ Upload image (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è ControlNet)\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # –æ—Ç–∫—Ä–æ–µ—Ç –æ–∫–Ω–æ \"Browse\"\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    control_path = os.path.join(\"/content\", filename)\n",
        "    file_size = os.path.getsize(control_path) / 1024\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "    print(f\"üìÇ Saved to: {control_path} ({file_size:.1f} KB)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded. –ò—Å–ø–æ–ª—å–∑—É–π control_path –≤—Ä—É—á–Ω—É—é –≤ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Rf83kaZOMIY5"
      },
      "id": "Rf83kaZOMIY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  üß≠  ControlNet\n",
        "from scripts.pipelines import run_controlnet\n",
        "\n",
        "control_path = \"\" #@param {type:\"string\"}\n",
        "low_thr      = 100   #@param {type:\"number\"}\n",
        "high_thr     = 200   #@param {type:\"number\"}\n",
        "seed         = 12345 #@param {type:\"number\"}\n",
        "\n",
        "saved = run_controlnet(\n",
        "    user_prompt=user_prompt,\n",
        "    style=base_style,\n",
        "    tone=color_tone,\n",
        "    negative=negative,\n",
        "    src_path=control_path,\n",
        "    CONFIG=CONFIG,\n",
        "    DEFAULTS=DEFAULTS,\n",
        "    strength=1.0,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ControlNet completed.\")\n",
        "print(\"üìÇ Saved files:\", saved if isinstance(saved, list) else [saved])\n",
        "print(f\"‚öôÔ∏è Thresholds: low={low_thr}, high={high_thr}\")\n"
      ],
      "metadata": {
        "id": "cs8iexWjMZ9q"
      },
      "id": "cs8iexWjMZ9q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚¨ÜÔ∏è 10 Upscale x4\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "up_id   = VARIANT_MODELS[variant][\"upscale\"]\n",
        "\n",
        "pipe_up = get_upscale_pipe(up_id, DEVICE, DTYPE)\n",
        "\n",
        "in_path = \"\"   #@param {type:\"string\"}\n",
        "seed    = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not in_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (in_path)\")\n",
        "\n",
        "img = Image.open(in_path).convert(\"RGB\")\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "out = pipe_up(image=img, prompt=final_prompt, generator=generator)\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"upscale_x4\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"upscale\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"Upscale saved: {p}\")\n"
      ],
      "metadata": {
        "id": "CKFMylGe4KfI"
      },
      "id": "CKFMylGe4KfI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
