{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOR-OFBjFAQ"
      },
      "source": [
        "# üé® SDXL Vintage Illustration Notebook ‚Äî PRO\n",
        "\n",
        "Stable Diffusion XL / Turbo / SD 1.5 preconfigured for **vintage ink+watercolor** illustrations (old book style, retro cartoon aesthetic).\n",
        "\n",
        "### Included\n",
        "- **Mode Selector** (CPU / GPU basic / GPU optimal via `CONFIG`)\n",
        "- **Gallery Manager (Flask web UI)** + **Logs** page\n",
        "- **Text2Img** (default vintage style + custom scene prompt)\n",
        "- **Img2Img** (photo ‚Üí vintage illustration)\n",
        "- **ControlNet (Canny)** for pose/contour consistency\n",
        "- **Upscale** (x4) for higher resolution\n",
        "- **Color tone control** (dropdown presets + custom override)\n",
        "- Saving images + JSON metadata to `/content/outputs` (timestamped)\n",
        "\n"
      ],
      "id": "vIOR-OFBjFAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚úÖ Tips\n",
        "\n",
        "- Change **`color_tone`** or **`custom_tone`** any time, then regenerate.\n",
        "- Use **`seed=None`** for randomization, or set a fixed integer for repeatability.\n",
        "- For **Img2Img**, tweak **`strength`**:\n",
        "  - lower = closer to original,\n",
        "  - higher = stronger style.\n",
        "- **ControlNet (Canny)** retains silhouette/contours. For different looks, adjust **`canny_low`/`canny_high`**.\n",
        "- If memory errors occur, run **`free_memory()`** and re-run only the needed loader.\n"
      ],
      "metadata": {
        "id": "PyfLfc6z13Ol"
      },
      "id": "PyfLfc6z13Ol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öô Vars\n",
        "REPO_NAME   = \"sd-colab-gallery\"\n",
        "ORIGIN_URL  = f\"https://github.com/tekswirl25/{REPO_NAME}.git\"\n",
        "repo_dir    = f\"/content/{REPO_NAME}\"\n",
        "OUTPUT_DIR  = \"/content/outputs\"\n",
        "LOG_DIR     = \"/content/logs\"\n"
      ],
      "metadata": {
        "id": "LTxF7NbxSYyo"
      },
      "id": "LTxF7NbxSYyo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Repo init\n",
        "import os, sys\n",
        "if not os.path.exists(repo_dir):\n",
        "    !git clone $ORIGIN_URL\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.append(repo_dir)\n",
        "\n",
        "from scripts.repo_init import init_repo\n",
        "repo_dir = init_repo(REPO_NAME, ORIGIN_URL, \"\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-M75dqeXXKXT"
      },
      "id": "-M75dqeXXKXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Config Init\n",
        "# -----------------------------\n",
        "# UI-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤—ã–±–æ—Ä—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º)\n",
        "PROGRAM_VERSION = \"SD15\"       #@param [\"SDXL\", \"SDXL_TURBO\", \"SD15\"]\n",
        "MODE            = \"GPU_OPTIMAL\" #@param [\"GPU_OPTIMAL\", \"GPU_BASIC\", \"CPU\"]\n",
        "OUTPUT_DIR      = \"/content/outputs\"\n",
        "# -----------------------------\n",
        "\n",
        "# HuggingFace token (Colab Secrets –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)\n",
        "hf_token = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get(\"HF_TOKEN\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "from scripts.config import init_config\n",
        "from scripts.logger import log_info, log_error\n",
        "\n",
        "CONFIG, VARIANT, DEFAULTS, AUTO_UPSCALE = init_config(\n",
        "    model_variant=PROGRAM_VERSION,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    hf_token=hf_token,\n",
        "    mode=MODE\n",
        ")\n",
        "\n",
        "log_info(f\"Torch version: {torch.__version__}\")\n",
        "log_info(f\"Device: {CONFIG['DEVICE']} | DType: {CONFIG['DTYPE']} | Mode: {CONFIG['MODE']}\")\n"
      ],
      "metadata": {
        "id": "uieDzdxEsR1w"
      },
      "id": "uieDzdxEsR1w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 3 Install dependencies (final)\n",
        "import os\n",
        "\n",
        "if MODE in [\"GPU_OPTIMAL\", \"GPU_BASIC\"]:\n",
        "    # GPU-–≤–∞—Ä–∏–∞–Ω—Ç—ã: Colab —Å–∞–º –ø–æ–¥–±–µ—Ä—ë—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π –±–∏–ª–¥ Torch –ø–æ–¥ CUDA\n",
        "    !pip install --quiet torch torchvision torchaudio\n",
        "else:\n",
        "    # CPU-—Ä–µ–∂–∏–º\n",
        "    !pip install --quiet torch torchvision torchaudio\n",
        "\n",
        "# HuggingFace —Å—Ç–µ–∫ + Gradio\n",
        "!pip install --quiet --upgrade diffusers transformers accelerate safetensors xformers gradio\n",
        "\n",
        "# –û–±—â–∏–µ –ø–∞–∫–µ—Ç—ã\n",
        "!pip install --quiet opencv-python-headless pillow ipywidgets\n",
        "\n",
        "print(f\"‚úÖ Dependencies installed for MODE={MODE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PhJHGzUTZaab"
      },
      "id": "PhJHGzUTZaab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üåê Start Gradio server (Logs + Gallery)\n",
        "refresh_interval = 5  #@param {type:\"integer\"}\n",
        "LOG_LINES = 50        #@param {type:\"integer\"}\n",
        "\n",
        "from scripts.server_gradio import start_gradio_server\n",
        "\n",
        "server = start_gradio_server(\"/content/outputs\", refresh_interval=refresh_interval, LOG_LINES=LOG_LINES)\n",
        "\n",
        "if server and hasattr(server, \"share_url\") and server.share_url:\n",
        "    print(f\"‚úÖ Gradio server running at: {server.share_url}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Gradio server started, but no public URL detected\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZ-fSmJ2ZcPi"
      },
      "id": "xZ-fSmJ2ZcPi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîç 1.1 –¢–µ—Å—Ç MODE\n",
        "from scripts.config import init_config\n",
        "\n",
        "# CPU —Ä–µ–∂–∏–º\n",
        "config_cpu, *_ = init_config(model_variant=\"SDXL\", mode=\"CPU\")\n",
        "print(\"CPU test:\", config_cpu[\"DEVICE\"], config_cpu[\"DTYPE\"])\n",
        "\n",
        "# GPU –±–∞–∑–æ–≤—ã–π\n",
        "config_gpu_basic, *_ = init_config(model_variant=\"SDXL\", mode=\"GPU_BASIC\")\n",
        "print(\"GPU_BASIC test:\", config_gpu_basic[\"DEVICE\"], config_gpu_basic[\"DTYPE\"])\n",
        "\n",
        "# GPU –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π\n",
        "config_gpu_opt, *_ = init_config(model_variant=\"SDXL\", mode=\"GPU_OPTIMAL\")\n",
        "print(\"GPU_OPTIMAL test:\", config_gpu_opt[\"DEVICE\"], config_gpu_opt[\"DTYPE\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Tl0chVwhN9ca"
      },
      "id": "Tl0chVwhN9ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîÅ 4 Imports & utils\n",
        "from scripts.utils import (\n",
        "    ts_now, base_name, save_image_and_meta,\n",
        "    free_memory, list_images, canny_from_image\n",
        ")\n",
        "from scripts.logger import log_info, log_error\n",
        "log_info(f\"Utils loaded. OUTPUT_DIR={CONFIG['OUTPUT_DIR']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XxvouF_9xe24"
      },
      "id": "XxvouF_9xe24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† 5 Model loaders\n",
        "from scripts.loaders import (\n",
        "    get_txt2img_pipe,\n",
        "    get_img2img_pipe,\n",
        "    get_controlnet_pipe,\n",
        "    get_upscale_pipe,\n",
        "    reset_pipes\n",
        ")\n",
        "log_info(f\"Loader functions ready for variant: {CONFIG['MODEL_VARIANT']}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNl-njQ9xr7X"
      },
      "id": "dNl-njQ9xr7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé® 6 Style base & Prompt builder\n",
        "from scripts.prompt_builder import build_style\n",
        "from scripts.logger import log_info\n",
        "\n",
        "base_style  = \"illustration\"  #@param [\"illustration\",\"photoreal\",\"anime\"]\n",
        "color_tone  = \"vintage\"       #@param [\"warm\",\"cool\",\"vintage\"]\n",
        "negative    = \"\"              #@param {type:\"string\"}\n",
        "\n",
        "# —Å—Ç—Ä–æ–∏–º style_suffix (–≥–ª–æ–±–∞–ª—å–Ω–æ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π)\n",
        "style_suffix = build_style(style=base_style, tone=color_tone)\n",
        "\n",
        "log_info(f\"Style ready | base={base_style}, tone={color_tone}, suffix={style_suffix}\")\n"
      ],
      "metadata": {
        "id": "yI_jrjtYS202"
      },
      "id": "yI_jrjtYS202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Text2Img\n",
        "from scripts.config import CONFIG, DEVICE, DTYPE, VARIANT_MODELS, DEFAULTS\n",
        "from scripts.loaders import get_txt2img_pipe\n",
        "from scripts.utils import save_image_and_meta, ts_now\n",
        "from scripts.logger import log_info\n",
        "import torch\n",
        "\n",
        "# user_prompt –≤—ã–Ω–µ—Å–µ–Ω —Å—é–¥–∞\n",
        "user_prompt = \"A thoughtful man, slightly resembling Donald Trump.\"  #@param {type:\"string\"}\n",
        "\n",
        "seed = 12345   #@param {type:\"number\"}  # 0 ‚Üí –∞–≤—Ç–æ—Ä–∞–Ω–¥–æ–º\n",
        "n    = 1   #@param {type:\"number\"}\n",
        "\n",
        "# —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∑–¥–µ—Å—å\n",
        "final_prompt = f\"{user_prompt}, {style_suffix}\" if style_suffix else user_prompt\n",
        "\n",
        "variant  = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "pipe     = get_txt2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "steps     = DEFAULTS[\"txt2img_steps\"]\n",
        "cfg_scale = DEFAULTS[\"txt2img_cfg\"]\n",
        "height, width = DEFAULTS[\"img_size\"]\n",
        "\n",
        "# —Å–∏–¥ ‚Äî —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–ª–∏ –∞–≤—Ç–æ + –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫\n",
        "base_seed = int(seed) if seed and int(seed) > 0 else int(torch.seed())\n",
        "\n",
        "saved = []\n",
        "for i in range(int(n)):\n",
        "    current_seed = base_seed + i\n",
        "    generator = torch.manual_seed(current_seed)\n",
        "\n",
        "    out = pipe(\n",
        "        prompt=final_prompt,\n",
        "        negative_prompt=(negative or None),\n",
        "        height=height, width=width,\n",
        "        guidance_scale=cfg_scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "    )\n",
        "    im = out.images[0]\n",
        "    meta = {\n",
        "        \"mode\": \"text2img\",\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative\": negative,\n",
        "        \"steps\": steps,\n",
        "        \"cfg_scale\": cfg_scale,\n",
        "        \"size\": [height, width],\n",
        "        \"seed\": current_seed,\n",
        "        \"timestamp\": ts_now(),\n",
        "    }\n",
        "    p, _ = save_image_and_meta(\n",
        "        im,\n",
        "        prefix=\"text2img\",\n",
        "        meta=meta,\n",
        "        output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
        "        mode=\"text2img\"\n",
        "    )\n",
        "    saved.append(p)\n",
        "\n",
        "log_info(f\"Text2Img saved: {saved}\")\n"
      ],
      "metadata": {
        "id": "qy3BdZzzSdqY"
      },
      "id": "qy3BdZzzSdqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì§ Upload image (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è Img2Img / ControlNet)\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# –ú–æ–∂–Ω–æ –∑–∞—Ä–∞–Ω–µ–µ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é:\n",
        "src_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "uploaded = files.upload()  # –æ—Ç–∫—Ä–æ–µ—Ç –æ–∫–Ω–æ \"Browse\"\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    src_path = os.path.join(\"/content\", filename)\n",
        "    file_size = os.path.getsize(src_path) / 1024\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "    print(f\"üìÇ Saved to: {src_path} ({file_size:.1f} KB)\")\n",
        "elif src_path:\n",
        "    print(f\"‚ö†Ô∏è No upload. –ò—Å–ø–æ–ª—å–∑—É—é –≤—Ä—É—á–Ω—É—é –∑–∞–¥–∞–Ω–Ω—ã–π –ø—É—Ç—å: {src_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded and src_path –ø—É—Å—Ç–æ–π. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")\n"
      ],
      "metadata": {
        "id": "A8gIu3i7LQqd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "A8gIu3i7LQqd"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Img2Img ‚Äî unified save & metadata (thumbnails, JSON, folders)\n",
        "from PIL import Image\n",
        "import torch\n",
        "from scripts.prompt_builder import build_prompt\n",
        "from scripts.loaders import get_img2img_pipe\n",
        "from scripts.utils import save_image_and_meta, ts_now\n",
        "from scripts.config import VARIANT_MODELS\n",
        "\n",
        "# UI\n",
        "strength = 0.6   #@param {type:\"number\"}\n",
        "seed     = 12345 #@param {type:\"number\"}\n",
        "src_path = \"\"    #@param {type:\"string\"}\n",
        "user_prompt = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# 1) Build final prompt (same logic as Text2Img)\n",
        "final_prompt = build_prompt(\n",
        "    text=user_prompt,\n",
        "    style=base_style,\n",
        "    tone=color_tone\n",
        ")\n",
        "\n",
        "# 2) Prepare pipeline\n",
        "variant  = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"img2img\"]\n",
        "\n",
        "image = Image.open(src_path).convert(\"RGB\")\n",
        "pipe_i2i = get_img2img_pipe(model_id, CONFIG[\"DEVICE\"], CONFIG[\"DTYPE\"])\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "# 3) Inference\n",
        "out = pipe_i2i(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=image,\n",
        "    strength=strength,\n",
        "    num_inference_steps=DEFAULTS[\"img2img_steps\"],\n",
        "    guidance_scale=DEFAULTS[\"img2img_cfg\"],\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "\n",
        "# 4) Save with thumbnails & JSON in proper subfolder\n",
        "meta = {\n",
        "    \"mode\": \"img2img\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"steps\": DEFAULTS[\"img2img_steps\"],\n",
        "    \"cfg_scale\": DEFAULTS[\"img2img_cfg\"],\n",
        "    \"strength\": strength,\n",
        "    \"seed\": seed,\n",
        "    \"source_path\": src_path,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "img_path, meta_path = save_image_and_meta(\n",
        "    im=im,\n",
        "    prefix=\"img2img\",\n",
        "    meta=meta,\n",
        "    output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
        "    mode=\"img2img\",             # üëà ensures /outputs/img2img and /thumbnails/img2img\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Img2Img completed.\")\n",
        "print(\"üìÇ Saved:\", img_path)\n",
        "print(\"üßæ Meta:\", meta_path)\n"
      ],
      "metadata": {
        "id": "sptyif7-DzjL"
      },
      "id": "sptyif7-DzjL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì§ Upload image (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è ControlNet)\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # –æ—Ç–∫—Ä–æ–µ—Ç –æ–∫–Ω–æ \"Browse\"\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    control_path = os.path.join(\"/content\", filename)\n",
        "    file_size = os.path.getsize(control_path) / 1024\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "    print(f\"üìÇ Saved to: {control_path} ({file_size:.1f} KB)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded. –ò—Å–ø–æ–ª—å–∑—É–π control_path –≤—Ä—É—á–Ω—É—é –≤ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Rf83kaZOMIY5"
      },
      "id": "Rf83kaZOMIY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß≠ ControlNet ‚Äî unified save & metadata (thumbnails, JSON, folders)\n",
        "from PIL import Image\n",
        "import torch\n",
        "from scripts.prompt_builder import build_prompt\n",
        "from scripts.loaders import get_controlnet_pipe\n",
        "from scripts.utils import save_image_and_meta, ts_now, canny_from_image\n",
        "from scripts.config import VARIANT_MODELS\n",
        "\n",
        "control_path = \"\" #@param {type:\"string\"}\n",
        "low_thr      = 100   #@param {type:\"number\"}\n",
        "high_thr     = 200   #@param {type:\"number\"}\n",
        "seed         = 12345 #@param {type:\"number\"}\n",
        "user_prompt = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# 1) Build final prompt (same logic as Text2Img)\n",
        "final_prompt = build_prompt(\n",
        "    text=user_prompt,\n",
        "    style=base_style,\n",
        "    tone=color_tone\n",
        ")\n",
        "\n",
        "# 2) Prepare pipeline (handle base/control ids across variants)\n",
        "variant         = CONFIG[\"MODEL_VARIANT\"]\n",
        "controlnet_id   = VARIANT_MODELS[variant][\"controlnet\"]\n",
        "base_id         = VARIANT_MODELS[variant].get(\"controlnet_model\", VARIANT_MODELS[variant][\"txt2img\"])\n",
        "\n",
        "pipe_cn = get_controlnet_pipe(\n",
        "    model_id=base_id,\n",
        "    controlnet_id=controlnet_id,\n",
        "    device=CONFIG[\"DEVICE\"],\n",
        "    dtype=CONFIG[\"DTYPE\"],\n",
        ")\n",
        "\n",
        "# 3) Source and (optional) Canny preprocessor as control image\n",
        "src_img = Image.open(control_path).convert(\"RGB\")\n",
        "control_img = canny_from_image(src_img, low=low_thr, high=high_thr)\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "# NOTE:\n",
        "# diffusers SDXL ControlNet expects `image` (init image for img2img-like conditioning is optional)\n",
        "# and `control_image` for the canny map. We pass both for robustness.\n",
        "out = pipe_cn(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=src_img,\n",
        "    control_image=control_img,\n",
        "    num_inference_steps=DEFAULTS[\"controlnet_steps\"],\n",
        "    guidance_scale=DEFAULTS[\"controlnet_cfg\"],\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "\n",
        "# 4) Save with thumbnails & JSON in proper subfolder\n",
        "meta = {\n",
        "    \"mode\": \"controlnet\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"steps\": DEFAULTS[\"controlnet_steps\"],\n",
        "    \"cfg_scale\": DEFAULTS[\"controlnet_cfg\"],\n",
        "    \"seed\": seed,\n",
        "    \"source_path\": control_path,\n",
        "    \"canny\": {\"low\": low_thr, \"high\": high_thr},\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "img_path, meta_path = save_image_and_meta(\n",
        "    im=im,\n",
        "    prefix=\"controlnet\",\n",
        "    meta=meta,\n",
        "    output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
        "    mode=\"controlnet\",          # üëà ensures /outputs/controlnet and /thumbnails/controlnet\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ControlNet completed.\")\n",
        "print(\"üìÇ Saved:\", img_path)\n",
        "print(\"üßæ Meta:\", meta_path)\n",
        "print(f\"‚öôÔ∏è Thresholds: low={low_thr}, high={high_thr}\")\n"
      ],
      "metadata": {
        "id": "km0zRYfJEqLk"
      },
      "id": "km0zRYfJEqLk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚¨ÜÔ∏è 10 Upscale x4\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "up_id   = VARIANT_MODELS[variant][\"upscale\"]\n",
        "\n",
        "pipe_up = get_upscale_pipe(up_id, DEVICE, DTYPE)\n",
        "\n",
        "in_path = \"\"   #@param {type:\"string\"}\n",
        "seed    = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not in_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (in_path)\")\n",
        "\n",
        "img = Image.open(in_path).convert(\"RGB\")\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "out = pipe_up(image=img, prompt=final_prompt, generator=generator)\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"upscale_x4\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(\n",
        "    im,\n",
        "    prefix=\"upscale\",\n",
        "    meta=meta,\n",
        "    output_dir=CONFIG[\"OUTPUT_DIR\"],\n",
        "    mode=\"upscale\"\n",
        ")\n",
        "log_info(f\"Upscale saved: {p}\")\n"
      ],
      "metadata": {
        "id": "CKFMylGe4KfI"
      },
      "id": "CKFMylGe4KfI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
