{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOR-OFBjFAQ"
      },
      "source": [
        "# üé® SDXL Vintage Illustration Notebook ‚Äî PRO\n",
        "\n",
        "Stable Diffusion XL / Turbo / SD 1.5 preconfigured for **vintage ink+watercolor** illustrations (old book style, retro cartoon aesthetic).\n",
        "\n",
        "### Included\n",
        "- **Mode Selector** (CPU / GPU basic / GPU optimal via `CONFIG`)\n",
        "- **Gallery Manager (Flask web UI)** + **Logs** page\n",
        "- **Text2Img** (default vintage style + custom scene prompt)\n",
        "- **Img2Img** (photo ‚Üí vintage illustration)\n",
        "- **ControlNet (Canny)** for pose/contour consistency\n",
        "- **Upscale** (x4) for higher resolution\n",
        "- **Color tone control** (dropdown presets + custom override)\n",
        "- Saving images + JSON metadata to `/content/outputs` (timestamped)\n",
        "\n"
      ],
      "id": "vIOR-OFBjFAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚úÖ Tips\n",
        "\n",
        "- Change **`color_tone`** or **`custom_tone`** any time, then regenerate.\n",
        "- Use **`seed=None`** for randomization, or set a fixed integer for repeatability.\n",
        "- For **Img2Img**, tweak **`strength`**:\n",
        "  - lower = closer to original,\n",
        "  - higher = stronger style.\n",
        "- **ControlNet (Canny)** retains silhouette/contours. For different looks, adjust **`canny_low`/`canny_high`**.\n",
        "- If memory errors occur, run **`free_memory()`** and re-run only the needed loader.\n"
      ],
      "metadata": {
        "id": "PyfLfc6z13Ol"
      },
      "id": "PyfLfc6z13Ol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Repo init\n",
        "import os\n",
        "\n",
        "repo_name = \"sd-colab-gallery\"\n",
        "repo_url  = f\"https://github.com/tekswirl25/{repo_name}.git\"\n",
        "repo_dir  = f\"/content/{repo_name}\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"üì• Cloning repo...\")\n",
        "    !git clone {repo_url} {repo_dir}\n",
        "else:\n",
        "    print(\"üîÑ Repo exists, pulling latest changes...\")\n",
        "    %cd {repo_dir}\n",
        "    !git pull\n",
        "\n",
        "%cd {repo_dir}\n",
        "print(\"‚úÖ Repo ready at\", repo_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "60M1dlBE8Hgs"
      },
      "id": "60M1dlBE8Hgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß 1 Config init\n",
        "import os, sys, torch\n",
        "sys.path.append(repo_dir)  # üöÄ Repo init\n",
        "\n",
        "# -----------------------------\n",
        "# UI-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤—ã–±–æ—Ä—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º)\n",
        "ENV_MODE        = \"GPU\"        #@param [\"GPU\", \"CPU\"]\n",
        "PROGRAM_VERSION = \"SDXL\"       #@param [\"SDXL\", \"SDXL_TURBO\", \"SD15\"]\n",
        "MODE            = \"GPU_OPTIMAL\" #@param [\"GPU_OPTIMAL\", \"GPU_BASIC\", \"CPU\"]\n",
        "OUTPUT_DIR      = \"/content/outputs\"\n",
        "# -----------------------------\n",
        "\n",
        "# HuggingFace token (Colab Secrets –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)\n",
        "hf_token = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get(\"HF_TOKEN\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "from scripts.config import init_config\n",
        "from scripts.logger import log_info, log_error\n",
        "\n",
        "CONFIG, VARIANT, DEFAULTS, AUTO_UPSCALE = init_config(\n",
        "    model_variant=PROGRAM_VERSION,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    hf_token=hf_token,\n",
        "    mode=MODE,\n",
        "    env_mode=ENV_MODE  # –Ω–æ–≤—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç\n",
        ")\n",
        "\n",
        "log_info(f\"Torch version: {torch.__version__}\")\n",
        "log_info(f\"Device: {CONFIG['DEVICE']} | DType: {CONFIG['DTYPE']} | Mode: {CONFIG['MODE']}\")\n"
      ],
      "metadata": {
        "id": "uieDzdxEsR1w"
      },
      "id": "uieDzdxEsR1w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîç 1.1 –¢–µ—Å—Ç ENV_MODE\n",
        "from scripts.config import init_config\n",
        "\n",
        "# CPU —Ä–µ–∂–∏–º\n",
        "config_cpu, *_ = init_config(model_variant=\"SDXL\", env_mode=\"CPU\")\n",
        "print(\"CPU test:\", config_cpu[\"DEVICE\"], config_cpu[\"DTYPE\"])\n",
        "\n",
        "# GPU —Ä–µ–∂–∏–º (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ CUDA)\n",
        "config_gpu, *_ = init_config(model_variant=\"SDXL\", env_mode=\"GPU\")\n",
        "print(\"GPU test:\", config_gpu[\"DEVICE\"], config_gpu[\"DTYPE\"])\n"
      ],
      "metadata": {
        "id": "Tl0chVwhN9ca"
      },
      "id": "Tl0chVwhN9ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 2 Server (Flask gallery + logs)\n",
        "from scripts.gallery_manager import start_gallery\n",
        "start_gallery(CONFIG[\"OUTPUT_DIR\"], port=8000, in_colab=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-PGUOEUskan"
      },
      "id": "F-PGUOEUskan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¶ 3 Install dependencies (Colab universal)\n",
        "!pip install --upgrade pip\n",
        "\n",
        "import os, sys, subprocess\n",
        "\n",
        "if ENV_MODE == \"GPU\":\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xformers\"])\n",
        "else:  # CPU fallback\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\",\n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cpu\"])\n",
        "    print(\"‚ö†Ô∏è CPU mode selected: xformers skipped\")\n",
        "\n",
        "# –û–±—â–∏–π —Å—Ç–µ–∫\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "    \"diffusers==0.29.0\", \"transformers\", \"accelerate\", \"safetensors\",\n",
        "    \"ipywidgets\", \"opencv-python-headless\", \"pillow\", \"flask\", \"nest_asyncio\"])\n",
        "\n",
        "import torch\n",
        "print(\"‚úÖ Dependencies installed. Torch version:\", torch.__version__)\n"
      ],
      "metadata": {
        "id": "zTZsBflTkxBK"
      },
      "id": "zTZsBflTkxBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîÅ 4 Imports & utils\n",
        "from scripts.utils import (\n",
        "    ts_now, base_name, save_image_and_meta,\n",
        "    free_memory, list_images, canny_from_image\n",
        ")\n",
        "from scripts.logger import log_info, log_error\n",
        "log_info(f\"Utils loaded. OUTPUT_DIR={CONFIG['OUTPUT_DIR']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XxvouF_9xe24"
      },
      "id": "XxvouF_9xe24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß† 5 Model loaders\n",
        "from scripts.loaders import (\n",
        "    get_txt2img_pipe,\n",
        "    get_img2img_pipe,\n",
        "    get_controlnet_pipe,\n",
        "    get_upscale_pipe,\n",
        "    reset_pipes\n",
        ")\n",
        "log_info(f\"Loader functions ready for variant: {CONFIG['MODEL_VARIANT']}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNl-njQ9xr7X"
      },
      "id": "dNl-njQ9xr7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üé® 6 Style base & Prompt builder\n",
        "from scripts.prompt_builder import build_prompt\n",
        "\n",
        "user_prompt = \"A thoughtful man, slightly resembling donald trump.\"  #@param {type:\"string\"}\n",
        "base_style  = \"illustration\"  #@param [\"photoreal\",\"illustration\",\"anime\"]\n",
        "color_tone  = \"vintage\"       #@param [\"warm\",\"cool\",\"vintage\"]\n",
        "negative    = \"\"              #@param {type:\"string\"}\n",
        "\n",
        "final_prompt = build_prompt(user_prompt, style=base_style, tone=color_tone)\n",
        "log_info(f\"Prompt built. style={base_style}, tone={color_tone}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Nx6OKvkvJZpx"
      },
      "id": "Nx6OKvkvJZpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Text2Img\n",
        "from PIL import Image\n",
        "from scripts.config import CONFIG, DEVICE, DTYPE, VARIANT_MODELS, DEFAULTS\n",
        "from scripts.loaders import get_txt2img_pipe\n",
        "from scripts.utils import save_image_and_meta, ts_now\n",
        "from scripts.logger import log_info\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "\n",
        "pipe = get_txt2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "steps     = DEFAULTS[\"txt2img_steps\"]\n",
        "cfg_scale = DEFAULTS[\"txt2img_cfg\"]\n",
        "height, width = DEFAULTS[\"img_size\"]\n",
        "\n",
        "seed = 12345      #@param {type:\"number\"}\n",
        "n    = 1          #@param {type:\"number\"}\n",
        "\n",
        "saved = []\n",
        "for _ in range(n):\n",
        "    generator = torch.manual_seed(seed)\n",
        "    out = pipe(\n",
        "        prompt=final_prompt,\n",
        "        negative_prompt=negative or None,\n",
        "        height=height, width=width,\n",
        "        guidance_scale=cfg_scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "    )\n",
        "    im = out.images[0]\n",
        "    meta = {\n",
        "        \"mode\": \"text2img\",\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative\": negative,\n",
        "        \"steps\": steps,\n",
        "        \"cfg_scale\": cfg_scale,\n",
        "        \"size\": [height, width],\n",
        "        \"seed\": seed,\n",
        "        \"timestamp\": ts_now(),\n",
        "    }\n",
        "    p, _ = save_image_and_meta(im, prefix=\"text2img\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "    saved.append(p)\n",
        "\n",
        "log_info(f\"Text2Img saved: {saved}\")\n"
      ],
      "metadata": {
        "id": "dh-8iJ3k3lPf"
      },
      "id": "dh-8iJ3k3lPf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Img2Img\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "model_id = VARIANT_MODELS[variant][\"img2img\"]\n",
        "\n",
        "src_path = \"\"    #@param {type:\"string\"}\n",
        "strength = 0.6   #@param {type:\"number\"}\n",
        "seed     = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not src_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (src_path)\")\n",
        "\n",
        "image = Image.open(src_path).convert(\"RGB\")\n",
        "pipe_i2i = get_img2img_pipe(model_id, DEVICE, DTYPE)\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "out = pipe_i2i(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=image,\n",
        "    strength=strength,\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"img2img\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"strength\": strength,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"img2img\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"Img2Img saved: {p}\")\n"
      ],
      "metadata": {
        "id": "laNfGN0x3vpo"
      },
      "id": "laNfGN0x3vpo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß≠ 9 ControlNet (Canny)\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "\n",
        "if variant == \"TURBO\":\n",
        "    base_model_id = VARIANT_MODELS[\"TURBO\"][\"controlnet_model\"]\n",
        "else:\n",
        "    base_model_id = VARIANT_MODELS[variant][\"txt2img\"]\n",
        "\n",
        "controlnet_id = VARIANT_MODELS[variant][\"controlnet\"]\n",
        "\n",
        "pipe_canny = get_controlnet_pipe(base_model_id, controlnet_id, DEVICE, DTYPE)\n",
        "\n",
        "control_path = \"\"   #@param {type:\"string\"}\n",
        "low_thr = 100       #@param {type:\"number\"}\n",
        "high_thr = 200      #@param {type:\"number\"}\n",
        "seed     = 12345    #@param {type:\"number\"}\n",
        "\n",
        "if not control_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è Canny (control_path)\")\n",
        "\n",
        "src = Image.open(control_path).convert(\"RGB\")\n",
        "canny_img = canny_from_image(src, low_thr, high_thr)\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "out = pipe_canny(\n",
        "    prompt=final_prompt,\n",
        "    negative_prompt=negative or None,\n",
        "    image=canny_img,\n",
        "    control_image=canny_img,\n",
        "    num_inference_steps=DEFAULTS[\"controlnet_steps\"],\n",
        "    guidance_scale=DEFAULTS[\"controlnet_cfg\"],\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"controlnet_canny\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"negative\": negative,\n",
        "    \"low_thr\": low_thr,\n",
        "    \"high_thr\": high_thr,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"controlnet\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"ControlNet saved: {p}\")\n"
      ],
      "metadata": {
        "id": "r1w0gFWF35cd"
      },
      "id": "r1w0gFWF35cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚¨ÜÔ∏è 10 Upscale x4\n",
        "from PIL import Image\n",
        "\n",
        "variant = CONFIG[\"MODEL_VARIANT\"]\n",
        "up_id   = VARIANT_MODELS[variant][\"upscale\"]\n",
        "\n",
        "pipe_up = get_upscale_pipe(up_id, DEVICE, DTYPE)\n",
        "\n",
        "in_path = \"\"   #@param {type:\"string\"}\n",
        "seed    = 12345 #@param {type:\"number\"}\n",
        "\n",
        "if not in_path:\n",
        "    raise ValueError(\"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (in_path)\")\n",
        "\n",
        "img = Image.open(in_path).convert(\"RGB\")\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "out = pipe_up(image=img, prompt=final_prompt, generator=generator)\n",
        "\n",
        "im = out.images[0]\n",
        "meta = {\n",
        "    \"mode\": \"upscale_x4\",\n",
        "    \"prompt\": final_prompt,\n",
        "    \"seed\": seed,\n",
        "    \"timestamp\": ts_now(),\n",
        "}\n",
        "p, _ = save_image_and_meta(im, prefix=\"upscale\", meta=meta, output_dir=CONFIG[\"OUTPUT_DIR\"])\n",
        "log_info(f\"Upscale saved: {p}\")\n"
      ],
      "metadata": {
        "id": "CKFMylGe4KfI"
      },
      "id": "CKFMylGe4KfI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
