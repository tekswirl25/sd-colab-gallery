{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® SDXL Vintage Illustration Notebook ‚Äî PRO\n",
        "\n",
        "Stable Diffusion XL 1.0 preconfigured for **vintage ink+watercolor** illustrations (old book style, retro cartoon aesthetic).\n",
        "\n",
        "### Included\n",
        "- **Mode Selector** (CPU / GPU basic / GPU optimal)\n",
        "- **Text2Img** (default vintage style + custom prompt)\n",
        "- **Img2Img** (photo ‚Üí vintage illustration)\n",
        "- **ControlNet (Canny)** for pose/contour consistency\n",
        "- **Upscale** (x4) for higher resolution\n",
        "- **Color tone control** (dropdown + custom)\n",
        "- Saving outputs to `/content/outputs` with timestamps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üîß Mode Selector (set once, can be changed any time)\n",
        "MODE = \"GPU_OPTIMAL\"  # options: \"CPU\", \"GPU_BASIC\", \"GPU_OPTIMAL\"\n",
        "print(f\"Selected MODE: {MODE}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üì¶ Install dependencies\n",
        "!pip -q install diffusers==0.29.0 transformers accelerate xformers safetensors opencv-python-headless ipywidgets\n",
        "import os, torch\n",
        "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "print(\"Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üîÅ Imports & utils\n",
        "import os, gc, time, random, datetime\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from diffusers import (\n",
        "    DiffusionPipeline,\n",
        "    StableDiffusionXLPipeline,\n",
        "    StableDiffusionXLImg2ImgPipeline,\n",
        "    StableDiffusionUpscalePipeline,\n",
        "    ControlNetModel,\n",
        "    StableDiffusionXLControlNetPipeline,\n",
        ")\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() and MODE != 'CPU' else 'cpu'\n",
        "DTYPE = torch.float16 if DEVICE == 'cuda' else torch.float32\n",
        "print(f\"DEVICE: {DEVICE}, DTYPE: {DTYPE}\")\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "def save_image(img: Image.Image, prefix: str = \"image\"):\n",
        "    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    path = os.path.join(OUTDIR, f\"{prefix}_{ts}.png\")\n",
        "    img.save(path)\n",
        "    print(\"Saved:\", path)\n",
        "    return path\n",
        "\n",
        "def set_seed(seed: int | None):\n",
        "    if seed is None:\n",
        "        return None\n",
        "    g = torch.Generator(device=DEVICE)\n",
        "    g.manual_seed(seed)\n",
        "    return g\n",
        "\n",
        "def free_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"Memory cleared.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üß† Model loaders (lazy)\n",
        "TXT2IMG_MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "UPSCALE_MODEL_ID = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "CONTROLNET_CANNY_ID = \"diffusers/controlnet-canny-sdxl-1.0\"  # SDXL canny ControlNet\n",
        "\n",
        "_txt2img_pipe = None\n",
        "_img2img_pipe = None\n",
        "_controlnet_pipe = None\n",
        "_upscale_pipe = None\n",
        "\n",
        "def get_txt2img_pipe():\n",
        "    global _txt2img_pipe\n",
        "    if _txt2img_pipe is None:\n",
        "        print(\"Loading SDXL txt2img pipeline‚Ä¶\")\n",
        "        _txt2img_pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            TXT2IMG_MODEL_ID, torch_dtype=DTYPE\n",
        "        )\n",
        "        try:\n",
        "            _txt2img_pipe.enable_xformers_memory_efficient_attention()\n",
        "        except Exception as e:\n",
        "            print(\"xFormers not enabled:\", e)\n",
        "        _txt2img_pipe.to(DEVICE)\n",
        "    return _txt2img_pipe\n",
        "\n",
        "def get_img2img_pipe():\n",
        "    global _img2img_pipe\n",
        "    if _img2img_pipe is None:\n",
        "        print(\"Loading SDXL img2img pipeline‚Ä¶\")\n",
        "        _img2img_pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "            TXT2IMG_MODEL_ID, torch_dtype=DTYPE\n",
        "        )\n",
        "        try:\n",
        "            _img2img_pipe.enable_xformers_memory_efficient_attention()\n",
        "        except Exception as e:\n",
        "            print(\"xFormers not enabled:\", e)\n",
        "        _img2img_pipe.to(DEVICE)\n",
        "    return _img2img_pipe\n",
        "\n",
        "def get_controlnet_pipe():\n",
        "    global _controlnet_pipe\n",
        "    if _controlnet_pipe is None:\n",
        "        print(\"Loading SDXL ControlNet (Canny)‚Ä¶\")\n",
        "        controlnet = ControlNetModel.from_pretrained(CONTROLNET_CANNY_ID, torch_dtype=DTYPE)\n",
        "        _controlnet_pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "            TXT2IMG_MODEL_ID, controlnet=controlnet, torch_dtype=DTYPE\n",
        "        )\n",
        "        try:\n",
        "            _controlnet_pipe.enable_xformers_memory_efficient_attention()\n",
        "        except Exception as e:\n",
        "            print(\"xFormers not enabled:\", e)\n",
        "        _controlnet_pipe.to(DEVICE)\n",
        "    return _controlnet_pipe\n",
        "\n",
        "def get_upscale_pipe():\n",
        "    global _upscale_pipe\n",
        "    if _upscale_pipe is None:\n",
        "        print(\"Loading x4 Upscaler‚Ä¶\")\n",
        "        _upscale_pipe = StableDiffusionUpscalePipeline.from_pretrained(UPSCALE_MODEL_ID, torch_dtype=DTYPE)\n",
        "        try:\n",
        "            _upscale_pipe.enable_xformers_memory_efficient_attention()\n",
        "        except Exception as e:\n",
        "            print(\"xFormers not enabled:\", e)\n",
        "        _upscale_pipe.to(DEVICE)\n",
        "    return _upscale_pipe\n",
        "\n",
        "print(\"Loader functions ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üé® Color tone control (widget-style via variables)\n",
        "# You can change these any time before generation\n",
        "COLOR_TONE_PRESETS = [\n",
        "    \"warm earthy tones\",\n",
        "    \"cool tones\",\n",
        "    \"sepia\",\n",
        "    \"black and white ink\",\n",
        "    \"muted colors\",\n",
        "    \"vivid watercolor\",\n",
        "]\n",
        "color_tone = \"warm earthy tones\"  # default\n",
        "custom_tone = \"\"  # if set non-empty, overrides color_tone\n",
        "print(\"Current color tone:\", custom_tone or color_tone)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üßæ Style base & prompt builder\n",
        "STYLE_BASE = (\n",
        "    \"Vintage-style illustration, hand-drawn with ink and watercolor effect on textured parchment background. \"\n",
        "    \"Caricatured and symbolic, with {tone}. \"\n",
        "    \"Characters in modest or historical attire, expressive faces, bold outlines, soft shading. \"\n",
        "    \"Old book illustration style, retro cartoon aesthetic.\"\n",
        ")\n",
        "\n",
        "def build_prompt(scene: str, tone: str | None = None):\n",
        "    tone_final = (custom_tone or tone or color_tone).strip()\n",
        "    return STYLE_BASE.format(tone=tone_final) + (\" \" + scene if scene else \"\")\n",
        "\n",
        "print(build_prompt(\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üñº Text2Img generation\n",
        "scene = \"A thoughtful woman in modest clothing, sitting with hand on chin, pensive pose.\"\n",
        "height, width = 1024, 1024\n",
        "steps = 30\n",
        "cfg_scale = 6.5\n",
        "seed = 12345  # set to None for random\n",
        "num_images = 1\n",
        "\n",
        "pipe = get_txt2img_pipe()\n",
        "generator = set_seed(seed)\n",
        "prompt = build_prompt(scene)\n",
        "print(\"PROMPT:\\n\", prompt)\n",
        "\n",
        "images = pipe(\n",
        "    prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=cfg_scale,\n",
        "    generator=generator,\n",
        ").images\n",
        "\n",
        "paths = []\n",
        "for i, im in enumerate(images[:num_images]):\n",
        "    p = save_image(im, prefix=\"text2img\")\n",
        "    paths.append(p)\n",
        "print(\"Done.\")\n",
        "paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üñº Img2Img (photo ‚Üí vintage)\n",
        "from io import BytesIO\n",
        "try:\n",
        "    from google.colab import files\n",
        "    COLAB = True\n",
        "except Exception:\n",
        "    COLAB = False\n",
        "\n",
        "input_image_path = \"\"  # optional: set a path like \"/content/my_photo.jpg\"; leave empty to upload via dialog\n",
        "strength = 0.5  # 0.3‚Äì0.8 (higher = more stylized)\n",
        "\n",
        "if not input_image_path:\n",
        "    if COLAB:\n",
        "        print(\"Upload an input image‚Ä¶\")\n",
        "        up = files.upload()\n",
        "        input_image_path = list(up.keys())[0]\n",
        "    else:\n",
        "        raise ValueError(\"Please set input_image_path or run in Colab to upload.\")\n",
        "\n",
        "init_img = Image.open(input_image_path).convert(\"RGB\")\n",
        "pipe_i2i = get_img2img_pipe()\n",
        "prompt = build_prompt(\"\")  # style only; you can append scene details\n",
        "print(\"PROMPT:\\n\", prompt)\n",
        "\n",
        "generator = set_seed(seed)\n",
        "res = pipe_i2i(\n",
        "    prompt=prompt,\n",
        "    image=init_img,\n",
        "    strength=strength,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=cfg_scale,\n",
        "    generator=generator,\n",
        ")\n",
        "out_img = res.images[0]\n",
        "save_image(out_img, prefix=\"img2img\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üß≠ ControlNet (Canny) for consistency\n",
        "def canny_from_image(pil_img: Image.Image, low=100, high=200):\n",
        "    arr = np.array(pil_img.convert('RGB'))\n",
        "    edges = cv2.Canny(arr, low, high)\n",
        "    edges_3c = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "    return Image.fromarray(edges_3c)\n",
        "\n",
        "control_input_path = \"\"  # optional; leave empty to upload\n",
        "canny_low, canny_high = 100, 200\n",
        "\n",
        "if not control_input_path:\n",
        "    if COLAB:\n",
        "        print(\"Upload an image for ControlNet Canny‚Ä¶\")\n",
        "        up2 = files.upload()\n",
        "        control_input_path = list(up2.keys())[0]\n",
        "    else:\n",
        "        raise ValueError(\"Please set control_input_path or run in Colab to upload.\")\n",
        "\n",
        "cn_img_src = Image.open(control_input_path).convert(\"RGB\")\n",
        "cn_img = canny_from_image(cn_img_src, canny_low, canny_high)\n",
        "display(cn_img)\n",
        "\n",
        "pipe_cn = get_controlnet_pipe()\n",
        "scene_cn = \"Group of legislators sitting around a wooden table, engaged in serious discussion.\"\n",
        "prompt_cn = build_prompt(scene_cn)\n",
        "print(\"PROMPT:\\n\", prompt_cn)\n",
        "\n",
        "generator = set_seed(seed)\n",
        "out = pipe_cn(\n",
        "    prompt=prompt_cn,\n",
        "    image=cn_img,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=cfg_scale,\n",
        "    generator=generator,\n",
        ")\n",
        "cn_out = out.images[0]\n",
        "save_image(cn_out, prefix=\"controlnet_canny\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ‚¨ÜÔ∏è Upscale x4\n",
        "up_input_path = \"\"  # set a path to image or leave empty to use the last saved image\n",
        "\n",
        "def find_latest_image(folder=OUTDIR):\n",
        "    imgs = [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith((\".png\",\".jpg\",\".jpeg\"))]\n",
        "    if not imgs:\n",
        "        return None\n",
        "    return max(imgs, key=os.path.getmtime)\n",
        "\n",
        "if not up_input_path:\n",
        "    up_input_path = find_latest_image()\n",
        "    assert up_input_path, \"No images found to upscale. Generate something first.\"\n",
        "\n",
        "img = Image.open(up_input_path).convert(\"RGB\")\n",
        "pipe_up = get_upscale_pipe()\n",
        "upscaled = pipe_up(prompt=\"\" , image=img).images[0]\n",
        "save_image(upscaled, prefix=\"upscaled_x4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Tips\n",
        "- Change `color_tone` or `custom_tone` any time, then regenerate.\n",
        "- Use `seed=None` for randomization or set a fixed integer for repeatability.\n",
        "- For Img2Img, tweak `strength`: lower = closer to original, higher = stronger style.\n",
        "- ControlNet canny retains silhouette/contours. For different looks, adjust `canny_low/high`.\n",
        "- If memory errors occur, run `free_memory()` and re-run only the needed loader.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
